{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzj-5O4__1Hw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vChGcOnSFdMP"
      },
      "source": [
        "# Bajamos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yirx50VhDzqm",
        "outputId": "070a0bed-09c5-48d1-bdd7-1e95356e1bc3"
      },
      "outputs": [],
      "source": [
        "# !wget -O datos.zip https://www.dropbox.com/scl/fi/v6qfj1ktarocr8sl02r8k/datos.zip?rlkey=2u060s5619gvcvnnnhq93rn4e&st=jy3dah88&dl=1\n",
        "# !unzip datos.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYTq5_WH_3gU"
      },
      "outputs": [],
      "source": [
        "class_names = [\"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlba-FnbFgZo"
      },
      "source": [
        "# Cargamos los archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr-bW_uYAFlX",
        "outputId": "d70b64cf-8790-4ee8-9089-391bc384cbaa"
      },
      "outputs": [],
      "source": [
        "X_train = np.loadtxt(\"datos/X_train.csv\", delimiter=\",\") #Funcón de numpy que carga texto (En nuestro caso las imagenes)\n",
        "y_train = np.loadtxt(\"datos/y_train.csv\", delimiter=\",\").astype(int) # Indice entero de que clase es cada imagen, hay 5000\n",
        "X_test = np.loadtxt(\"datos/X_test.csv\", delimiter=\",\") # Variables test son las de prueba, NO USAR\n",
        "y_test = np.loadtxt(\"datos/y_test.csv\", delimiter=\",\").astype(int) # Indice de las imagenes de PRUEBA\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8i93JF5Eyr2"
      },
      "source": [
        "# Revisamos la cantida de muestras por cada clase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKPyYqBSFG_d",
        "outputId": "dcd9d40b-3ee5-4938-c778-91a540e5ae8e"
      },
      "outputs": [],
      "source": [
        "np.bincount(y_train), np.bincount(y_test) # Cuenta cuántos ceros hay, cuántos unos hay, etc.. Hay 500 de cada uno en los datos de entrenamiento y 50 de cada uno en los datos de prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luYIJeYPGQ_X"
      },
      "source": [
        "# Visualizamos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "UFd0dyATCDZT",
        "outputId": "3102540f-9a29-4ecc-b413-50f4988c2ee9"
      },
      "outputs": [],
      "source": [
        "ix = 7 #Agarro el elemento numero 7\n",
        "plt.imshow(X_test[ix].reshape(28,28), cmap=\"gray\") #Reshape para acomodarlo en 28 * 28 (cuadrado)\n",
        "plt.title(class_names[y_test[ix]]); #Le pone el nombre ... chequea que está bien (coincide el titulo con la imagen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvEd8-b3KYkB"
      },
      "source": [
        "# Separamos en datos de desarrollo\n",
        "\n",
        "Garantizamos que las clases siguen igualmente balanceadas (estratificación)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leTGrXS2KVZc",
        "outputId": "87a8837e-4a95-4c11-b3f3-0fd3a8494db0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_newtrain, X_dev, y_newtrain, y_dev = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train) # Test size = 20%, divide un quinto para reservar como desarrollo.\n",
        "#Stratify garantiza que todo lo que metió en ese 20% tiene la misma cantidad de prendas de ropa que en el resto\n",
        "\n",
        "np.bincount(y_newtrain), np.bincount(y_dev) #New Train = E , y_dev = Desarrollo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLCx48t_GTkd"
      },
      "source": [
        "# 1.KNN\n",
        "\n",
        "### Implementación en Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39TWfS9JSD2L"
      },
      "outputs": [],
      "source": [
        "def distance(A, B):\n",
        "    dot_product = A.dot(B)\n",
        "    norm_product = np.linalg.norm(A) * np.linalg.norm(B)\n",
        "    return 1 - (dot_product / norm_product)\n",
        "\n",
        "\n",
        "#image set = lista de tuplas, con cada tupla = (imagen(vector), typo de imagen)\n",
        "def image_distances(image_set, image):\n",
        "    distances = []\n",
        "    dis = 0\n",
        "    for pic, label in image_set:\n",
        "        dis = distance(image, pic)\n",
        "        distances.append((dis, label))\n",
        "    return distances\n",
        "\n",
        "#distances = lista de tuplas, con cada tupla = (distanca de cada imagen de entrenamiento con la imagen elegida, typo de imagen)\n",
        "def classify_image(distances, k):\n",
        "    distances.sort(key=lambda x: x[0])\n",
        "    number_of_apperances = np.zeros(10)\n",
        "    for i in range(0, k): # k = cantidad de vecinos que queremos analizar \n",
        "       image_type = distances[i][1]\n",
        "       number_of_apperances[image_type] = number_of_apperances[image_type] + 1  \n",
        "\n",
        "    max = -1\n",
        "    max_index = -1\n",
        "    for i in range(0, len(number_of_apperances)):\n",
        "        if(number_of_apperances[i] > max):\n",
        "            max = number_of_apperances[i]\n",
        "            max_index = i\n",
        "    \n",
        "    return max_index\n",
        "\n",
        "def first_test(image, image_type):\n",
        "    images = X_train[:4000]\n",
        "    types = y_train[:4000]\n",
        "    image_set = zip(images, types) #creamos las tuplas\n",
        "    distances = image_distances(image_set, image)\n",
        "    expected_type = classify_image(distances, 5)\n",
        "    return expected_type\n",
        "    # print(f\"succes: {image_type == expected_type}; original type: {image_type}; expected type: {expected_type}\")\n",
        "\n",
        "expected_types = []\n",
        "for i in range(4000, 5000):\n",
        "    image = X_train[i]\n",
        "    image_type = y_train[i]\n",
        "    expected_types.append((first_test(image, image_type), image_type))\n",
        "\n",
        "print(expected_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def distanceMatrix(A, B):   # Apilar verticalmente los vectores en una matriz\n",
        "    # Calcular las normas de cada vector de las matrices A y B\n",
        "    norms_a = np.linalg.norm(A, axis=1)\n",
        "    norms_b = np.linalg.norm(B, axis=1)\n",
        "    # Dividir cada componente de las matrices por la norma del vector correspondiente\n",
        "    A_normalized = A / norms_a[:, np.newaxis]\n",
        "    B_normalized = B / norms_b[:, np.newaxis]\n",
        "    # Calcula la matriz traspuesta de B\n",
        "    B_normalized_t = np.transpose(B_normalized)\n",
        "    # Calcula la distancias haciendo una multiplicació n entre ambas matrices\n",
        "    distances = A_normalized @ B_normalized_t\n",
        "    # Hace 1 - distances\n",
        "    # ones = np.ones((len(distances), len(distances)))\n",
        "    distances = 1 - distances\n",
        "    \n",
        "    return distances\n",
        "\n",
        "#######REVISAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAR ESTE IF NO ES LA MEJOR IMPLEMENTACION\n",
        "def knn(k, distances_matrix, start_index_desarrollo, end_index_desarrollo):\n",
        "    # Recorta la matriz segun nuestra conveniencia \n",
        "    sub_matrix = distances_matrix[start_index_desarrollo:end_index_desarrollo+1]\n",
        "    # Eliminar las columnas desde col_start_index hasta col_end_index (inclusive col_end_index)\n",
        "    #######REVISAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAR ESTE IF NO ES LA MEJOR IMPLEMENTACION\n",
        "    if not(start_index_desarrollo == 0 and end_index_desarrollo == len(distances_matrix)):\n",
        "        sub_matrix = np.delete(sub_matrix, np.s_[start_index_desarrollo:end_index_desarrollo+1], axis=1)\n",
        "    # Ordena por distancias de más cercana a más lejana y hace módulo 10 \n",
        "    sub_matrix = np.argsort(sub_matrix, axis=1) % 10\n",
        "    # Se queda con las primeras k columnas más cercanas\n",
        "    k_sub_matrix = sub_matrix[:, :k]\n",
        "    # Calcula la moda \n",
        "    mode, frecuency = scipy.stats.mode(k_sub_matrix, axis=1)\n",
        "    return mode\n",
        "\n",
        "print(knn(5,distanceMatrix(X_train, X_train),4000,5000))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#test matriz distancias\n",
        "def second_test():\n",
        "    distancias_clasica = np.zeros((5000, 5000))\n",
        "    for i in range(0, 5000):\n",
        "        for j in range(0, 5000): \n",
        "            distancias_clasica[i][j] = distance(X_train[i], X_train[j])\n",
        "    return distancias_clasica\n",
        "\n",
        "\n",
        "def son_iguales(distancias_clasica):\n",
        "    distance_maitrx = distanceMatrix(X_train, X_train )\n",
        "    matriz_de_comparacion = np.full((5000, 5000), False, dtype=bool)\n",
        "    for i in range(0, 5000):\n",
        "        for j in range(0, 5000):\n",
        "            if np.isclose(distancias_clasica[i][j], distance_maitrx[i][j], atol=0.00001):\n",
        "                matriz_de_comparacion[i][j] = True\n",
        "    # print(distance_matrix)\n",
        "    print(matriz_de_comparacion)\n",
        "\n",
        "# second_test()\n",
        "old_distances = second_test()\n",
        "son_iguales(old_distances)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Reconocimiento de imágenes en Fashion MNist\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### a - Realizar un reconocedor de imágenes usando KNN para un k fijo de 5, usando los datos de entrenamiento dados y medir la performance con la medida de exactitud en el conjunto de prueba. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def image_recognizer():\n",
        "    # Calculamos las distancias entre las imágenes en X_ train y  X_test\n",
        "    distances_matrix = distanceMatrix(X_test, X_train)\n",
        "    # Hacemos KNN, siendo los elementos de prueba los que van de 5001 al 5500\n",
        "    res_knn = knn(5,distances_matrix, 0, len(distances_matrix)) \n",
        "\n",
        "    # Para medir la performance, comparo el resultado de knn (modas) contra el resultado real (y_test)\n",
        "    correctos = np.sum(res_knn == y_test) # Calcula la cantidad de elementos que son iguales en la misma posición\n",
        "    performance = correctos / 500\n",
        "\n",
        "    print(\"Predicciones correctas =\", correctos)\n",
        "    print(\"Performance =\", performance)\n",
        "\n",
        "image_recognizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### b - Explorar el hiperparámetro k, usando 5-fold cross-validation con el conjunto de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implementación en Python\n",
        "# def calculate_With_traingin_development(training, development, k):\n",
        "#     ammount_of_succeses = 0\n",
        "#     for image in development:\n",
        "#         distances = image_distances(training, image)\n",
        "#         expected_type = classify_image(distances, k)\n",
        "#         if (expected_type == image[1]):\n",
        "#             ammount_of_succeses = ammount_of_succeses + 1\n",
        "#     return ammount_of_succeses / 1000\n",
        "\n",
        "# for i in range(0, 5):\n",
        "#     full_image_set = list(zip(X_train, y_train))\n",
        "#     inicio_D = i * 1000\n",
        "#     fin_D = inicio_D + 1000\n",
        "    \n",
        "#     # Creando la lista D\n",
        "#     D = full_image_set[inicio_D:fin_D]\n",
        "    \n",
        "#     # Creando la lista T\n",
        "#     T = full_image_set[:inicio_D] + full_image_set[fin_D:]\n",
        "\n",
        "#     calculate_With_traingin_development(T, D, 5)\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Revisar creo que está mal xq los resultados dan raro\n",
        "def cross_validation():\n",
        "    precomputo = distanceMatrix(X_train, X_train)\n",
        "    averages = []\n",
        "    for k in range (1,10): \n",
        "        performances = []\n",
        "        for i in range (0,5):\n",
        "            start = i*1000\n",
        "            end = (i+1)*1000\n",
        "            res_knn = knn(k, precomputo, start, end)\n",
        "            # Calcula la cantidad de elementos calculados que coinciden con su tipo original\n",
        "            correctos = np.sum(res_knn == y_train[start:end+1])\n",
        "            performance = correctos / 1000\n",
        "            performances.append(performance)\n",
        "        average = np.mean(performances)\n",
        "        averages.append((k, average))\n",
        "\n",
        "    best_k_index = np.argmax([avg[1] for avg in averages])\n",
        "    best_k = averages[best_k_index][0]\n",
        "    return best_k\n",
        "\n",
        "cross_validation()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### c - Preprocesar los datos de entrenamiento con PCA. Visualizar la cantidad de varianza explicada en función de la cantidad de componentes p\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se resta a cada valor la media de la imagen a la que pertenece (por fila)\n",
        "X_centered = X_test - np.mean(X_test, axis=1)\n",
        "\n",
        "# Se calcula la matriz de covarianza\n",
        "covariance_matrix = np.cov(X_centered)\n",
        "\n",
        "# Encontrar autovalores y autovectores USANDO EL MÉTODO DE LA POTENCIA \n",
        "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
        "\n",
        "# V matriz de autovectores , D matriz de autovalores (ordenarlas por importancia)\n",
        "\n",
        "# Reducir la dimensionalidad de los datos a p componentes = mult X_train por V utilizando los primeros p vectores columna de la matriz V\n",
        "\n",
        "# Calcular la varianza explicada en función de las p componentes   \n",
        "\n",
        "# Hacerlo para distintos valores de P"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### d - Pipeline final: Exploración conjunta de los hiperparámetros k de KNN, y p de PCA.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pybind11 está instalado\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Método de la potencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !rm metodo_potencia.so \n",
        "# !g++ -shared =fPIC -Llibdl -o metodo_potencia.so metodo_potencia.cpp\n",
        "# !ls "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import ctypes\n",
        "\n",
        "# class sharedlib():\n",
        "#     dlclose = ctypes.CDLL(None).dlclose  # This WON'T work on Win\n",
        "#     dlclose.argtypes = (ctypes.c_void_p,)\n",
        "\n",
        "#     def __init__(self, path, method, *args):\n",
        "#         self.lib = ctypes.cdll.LoadLibrary(f'./{path}')\n",
        "\n",
        "#         # Se explicitan los tipos de los argumentos para el método deseado\n",
        "#         self.method_object = getattr(self.lib, method)\n",
        "#         self.method_object.argtypes = args\n",
        "\n",
        "#     def __call__(self, *args):\n",
        "#         return self.method_object(*args)\n",
        "\n",
        "#     def unload(self):\n",
        "#         while self.dlclose(self.lib._handle)!=-1:\n",
        "#             pass\n",
        "\n",
        "# lib = sharedlib('metodo_potencia.so', 'power_iteration_deflation',\n",
        "#                                                                 ctypes.POINTER(ctypes.c_double),\n",
        "#                                                                 ctypes.POINTER(ctypes.c_double),\n",
        "#                                                                 ctypes.POINTER(ctypes.c_double),\n",
        "#                                                                 ctypes.c_int,\n",
        "#                                                                 ctypes.c_int\n",
        "#                                                             )\n",
        "\n",
        "# # Creamos la matriz de entrada\n",
        "# A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=np.float64)\n",
        "# # Eigen la mapea transpuesta a la información del puntero así que hay que pasarlo a orden tipo Fortran\n",
        "# A = np.asfortranarray(A)\n",
        "# b = np.array([1, 2, 3], dtype=np.float64)\n",
        "\n",
        "# # Definimos el vector donde se van a guardar los resultados\n",
        "# result = np.zeros((3,), dtype=np.float64)\n",
        "\n",
        "# # Llamamos a nuestra función en C++ pasando los argumentos de entrada\n",
        "# lib(\n",
        "#     A.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
        "#     b.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
        "#     result.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
        "#     ctypes.c_int(A.shape[0]),\n",
        "#     ctypes.c_int(A.shape[1])\n",
        "# )\n",
        "\n",
        "# lib.unload() # para poder recompilar la lib hay que cerrarla\n",
        "\n",
        "# result"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
